{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba016250-6365-4a07-a3b6-914e3837d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping opencv-python-headless as it is not installed.\n",
      "WARNING: Skipping opencv-python as it is not installed.\n",
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Suktad\\anaconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Suktad\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Skipping jax-cuda12-plugin as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y opencv-python-headless opencv-python opencv-contrib-python mediapipe numpy jax jaxlib jax-cuda12-plugin protobuf -q\n",
    "\n",
    "\n",
    "!pip install --no-cache-dir \\\n",
    "  numpy==1.26.4 \\\n",
    "  \"protobuf>=4.25.3,<5\" \\\n",
    "  mediapipe==0.10.21 \\\n",
    "  opencv-contrib-python==4.11.0.86 -q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b29d5182-29ac-420d-8fb9-ed6ed0d46933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SESSION SUMMARY ===\n",
      "Total Reps: 3\n",
      "Average Depth (knee angle): 84.5°\n",
      "Average Lean: 17.6°\n",
      "Good Reps: 1 / 3 (33.3%)\n",
      "Video saved: smart_squat_fullscreen.mp4\n",
      "CSV log: rep_log.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 110\u001b[0m\n\u001b[0;32m    108\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m    109\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m results \u001b[38;5;241m=\u001b[39m pose\u001b[38;5;241m.\u001b[39mprocess(image)\n\u001b[0;32m    111\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    112\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mprocess(input_data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: image})\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mwait_until_idle()\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"jaxlib.plugin_support\")\n",
    "\n",
    "import platform, time, csv, os\n",
    "import cv2, numpy as np, mediapipe as mp\n",
    "from collections import deque\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def calculate_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    return 360 - angle if angle > 180.0 else angle\n",
    "\n",
    "def torso_lean_deg(shoulder, hip):\n",
    "    v = np.array([shoulder[0]-hip[0], shoulder[1]-hip[1]])\n",
    "    up = np.array([0.0, -1.0])\n",
    "    nv = np.linalg.norm(v)\n",
    "    if nv < 1e-6: return 0.0\n",
    "    cosang = np.clip(np.dot(v, up)/(nv*1.0), -1.0, 1.0)\n",
    "    return float(np.degrees(np.arccos(cosang)))\n",
    "\n",
    "def open_camera_for_jupyter():\n",
    "    osname = platform.system().lower()\n",
    "    if osname.startswith(\"win\"):\n",
    "        backends = [cv2.CAP_DSHOW, cv2.CAP_MSMF, None]\n",
    "    elif osname == \"darwin\":\n",
    "        backends = [cv2.CAP_AVFOUNDATION, None]\n",
    "    else:\n",
    "        backends = [cv2.CAP_V4L2, None]\n",
    "    for b in backends:\n",
    "        for idx in (0,1,2):\n",
    "            cap = cv2.VideoCapture(idx) if b is None else cv2.VideoCapture(idx, b)\n",
    "            if cap.isOpened():\n",
    "                cap.set(cv2.CAP_PROP_FRAME_WIDTH,  960)\n",
    "                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "                cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "                return cap\n",
    "            cap.release()\n",
    "    return None\n",
    "\n",
    "# ---------- thresholds ----------\n",
    "TOP_LOCK   = 165\n",
    "BOTTOM_TH  = 95\n",
    "LEAN_WARN  = 20\n",
    "VIS_THR    = 0.7\n",
    "QUALITY_POP_MS = 1500\n",
    "# -------------------------------\n",
    "\n",
    "def classify_rep(min_knee_angle, max_lean_deg):\n",
    "    good_depth = min_knee_angle < (BOTTOM_TH - 5)\n",
    "    ok_depth   = min_knee_angle < 115\n",
    "    upright    = max_lean_deg < LEAN_WARN\n",
    "    a_bit_lean = max_lean_deg < (LEAN_WARN + 5)\n",
    "\n",
    "    if good_depth and upright:\n",
    "        return \"Good\"\n",
    "    if (good_depth and a_bit_lean) or (ok_depth and upright):\n",
    "        return \"Okay\"\n",
    "    return \"Bad\"\n",
    "\n",
    "# ---------- setup ----------\n",
    "cap = open_camera_for_jupyter()\n",
    "if cap is None:\n",
    "    raise RuntimeError(\"Could not open webcam. Close Zoom/Meet/OBS, check permissions.\")\n",
    "\n",
    "ok, probe = cap.read()\n",
    "if not ok:\n",
    "    cap.release()\n",
    "    raise RuntimeError(\"Webcam opened but no frames received.\")\n",
    "\n",
    "h, w = probe.shape[:2]\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "video_path = \"smart_squat_fullscreen.mp4\"\n",
    "out = cv2.VideoWriter(video_path, fourcc, 20.0, (w, h))\n",
    "\n",
    "counter, state = 0, \"get_ready\"\n",
    "status_text, form_text = \"\", \"\"\n",
    "\n",
    "knee_hist = deque(maxlen=5)\n",
    "lean_hist = deque(maxlen=5)\n",
    "\n",
    "curr_min_knee, curr_max_lean = 999.0, 0.0\n",
    "show_quality_until, last_quality_text = 0.0, \"\"\n",
    "last_quality_color = (0, 180, 0)\n",
    "\n",
    "rep_records = []\n",
    "\n",
    "csv_path = \"rep_log.csv\"\n",
    "write_header = not os.path.exists(csv_path)\n",
    "csv_file = open(csv_path, \"a\", newline=\"\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "if write_header:\n",
    "    csv_writer.writerow([\"rep_index\",\"min_knee_angle_deg\",\"max_lean_deg\",\"quality\",\"timestamp\"])\n",
    "\n",
    "# full screen window\n",
    "cv2.namedWindow(\"Smart Squat Trainer\", cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty(\"Smart Squat Trainer\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    try:\n",
    "        while True:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok: break\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            results = pose.process(image)\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            try:\n",
    "                lm = results.pose_landmarks.landmark\n",
    "                LHIP, LKNE, LANK, LSHO = lm[23], lm[25], lm[27], lm[11]\n",
    "                RHIP, RKNE, RANK, RSHO = lm[24], lm[26], lm[28], lm[12]\n",
    "\n",
    "                l_hip, l_knee, l_ankle = [LHIP.x, LHIP.y], [LKNE.x, LKNE.y], [LANK.x, LANK.y]\n",
    "                r_hip, r_knee, r_ankle = [RHIP.x, RHIP.y], [RKNE.x, RKNE.y], [RANK.x, RANK.y]\n",
    "                l_sho, r_sho = [LSHO.x, LSHO.y], [RSHO.x, RSHO.y]\n",
    "\n",
    "                l_knee_ang = calculate_angle(l_hip, l_knee, l_ankle)\n",
    "                r_knee_ang = calculate_angle(r_hip, r_knee, r_ankle)\n",
    "                knee = (l_knee_ang + r_knee_ang) / 2.0\n",
    "                l_lean = torso_lean_deg(l_sho, l_hip)\n",
    "                r_lean = torso_lean_deg(r_sho, r_hip)\n",
    "                lean = (l_lean + r_lean) / 2.0\n",
    "\n",
    "                hip_below_knee = (l_hip[1] > l_knee[1]) and (r_hip[1] > r_knee[1])\n",
    "                is_visible = all(pt.visibility > VIS_THR for pt in [LHIP, LKNE, RHIP, RKNE, LSHO, RSHO])\n",
    "\n",
    "                knee_hist.append(knee)\n",
    "                lean_hist.append(lean)\n",
    "                s_knee, s_lean = float(np.mean(knee_hist)), float(np.mean(lean_hist))\n",
    "\n",
    "                # rep tracking\n",
    "                if state == \"get_ready\":\n",
    "                    if is_visible and s_knee > (TOP_LOCK - 5):\n",
    "                        state, status_text = \"ready\", \"READY\"\n",
    "                        curr_min_knee, curr_max_lean = 999.0, 0.0\n",
    "                    else:\n",
    "                        status_text = \"STAND STRAIGHT TO START\"\n",
    "\n",
    "                elif state == \"ready\":\n",
    "                    status_text = \"DESCEND\"\n",
    "                    curr_min_knee = min(curr_min_knee, s_knee)\n",
    "                    curr_max_lean = max(curr_max_lean, s_lean)\n",
    "                    if s_knee < BOTTOM_TH or hip_below_knee:\n",
    "                        state = \"down\"\n",
    "\n",
    "                el\n",
    "                if state == \"down\":\n",
    "                    status_text = \"DRIVE UP\"\n",
    "                    curr_min_knee = min(curr_min_knee, s_knee)\n",
    "                    curr_max_lean = max(curr_max_lean, s_lean)\n",
    "                    if s_knee > (TOP_LOCK - 5):\n",
    "                        counter += 1\n",
    "                        quality = classify_rep(curr_min_knee, curr_max_lean)\n",
    "                        last_quality_text = f\"REP {counter}: {quality}\"\n",
    "                        last_quality_color = {\"Good\":(0,200,0),\"Okay\":(0,165,255),\"Bad\":(0,0,255)}.get(quality,(255,255,255))\n",
    "                        show_quality_until = time.time() + QUALITY_POP_MS/1000.0\n",
    "\n",
    "                        csv_writer.writerow([counter, round(curr_min_knee,1), round(curr_max_lean,1), quality, round(time.time(),3)])\n",
    "                        csv_file.flush()\n",
    "                        rep_records.append((curr_min_knee, curr_max_lean, quality))\n",
    "                        state, status_text = \"ready\", \"REP COUNTED!\"\n",
    "                        curr_min_knee, curr_max_lean = 999.0, 0.0\n",
    "\n",
    "                # live cues\n",
    "                if not is_visible:\n",
    "                    form_text = \"MOVE INTO FRAME\"\n",
    "                elif s_lean > LEAN_WARN:\n",
    "                    form_text = \"CHEST UP\"\n",
    "                elif state in (\"ready\",\"down\") and s_knee > 120:\n",
    "                    form_text = \"GO DEEPER\"\n",
    "                elif s_knee < BOTTOM_TH or hip_below_knee:\n",
    "                    form_text = \"GOOD DEPTH\"\n",
    "                else:\n",
    "                    form_text = \"GOOD FORM\"\n",
    "\n",
    "            except Exception:\n",
    "                state, status_text, form_text = \"get_ready\", \"NO BODY DETECTED\", \"—\"\n",
    "\n",
    "            # color logic\n",
    "            if form_text in (\"GOOD FORM\", \"GOOD DEPTH\"): bar_color = (0, 180, 0)\n",
    "            elif form_text == \"GO DEEPER\":               bar_color = (0, 0, 255)\n",
    "            elif form_text == \"CHEST UP\":                bar_color = (0, 165, 255)\n",
    "            else:                                        bar_color = (128, 0, 128)\n",
    "\n",
    "            # UI boxes\n",
    "            cv2.rectangle(image, (0, 0), (260, 78), (40, 40, 40), -1)\n",
    "            cv2.putText(image, 'REPS', (15, 22), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1)\n",
    "            cv2.putText(image, str(counter), (12, 64), cv2.FONT_HERSHEY_SIMPLEX, 1.6, (255,255,255), 2)\n",
    "            cv2.putText(image, 'STATUS', (130, 22), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1)\n",
    "            cv2.putText(image, status_text, (122, 62), cv2.FONT_HERSHEY_SIMPLEX, 0.95, (255,255,255), 2)\n",
    "\n",
    "            # form bar\n",
    "            cv2.rectangle(image, (260, 0), (max(960, image.shape[1]), 78), bar_color, -1)\n",
    "            (tw, _), _ = cv2.getTextSize(form_text, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)\n",
    "            text_x = 260 + (min(image.shape[1], 960) - 260 - tw) // 2\n",
    "            cv2.putText(image, form_text, (max(260, text_x), 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,255,255), 2)\n",
    "\n",
    "            # progress bar for squat depth\n",
    "            progress = np.clip((TOP_LOCK - s_knee) / (TOP_LOCK - BOTTOM_TH), 0, 1)\n",
    "            bar_w, bar_h = 25, int(progress * (image.shape[0]-100))\n",
    "            cv2.rectangle(image, (image.shape[1]-60, image.shape[0]-50-bar_h), (image.shape[1]-35, image.shape[0]-50), (0,255,0) if progress>0.9 else (0,200,255), -1)\n",
    "            cv2.rectangle(image, (image.shape[1]-60, image.shape[0]-50-(image.shape[0]-100)), (image.shape[1]-35, image.shape[0]-50), (255,255,255), 2)\n",
    "            cv2.putText(image, f\"{int(progress*100)}%\", (image.shape[1]-85, image.shape[0]-60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "            # rep quality popup\n",
    "            if time.time() < show_quality_until and last_quality_text:\n",
    "                (qw, qh), _ = cv2.getTextSize(last_quality_text, cv2.FONT_HERSHEY_SIMPLEX, 1.1, 3)\n",
    "                cx, y = image.shape[1] // 2, image.shape[0] - 60\n",
    "                cv2.rectangle(image, (cx - qw//2 - 12, y - qh - 14), (cx + qw//2 + 12, y + 10), (30, 30, 30), -1)\n",
    "                cv2.putText(image, last_quality_text, (cx - qw//2, y), cv2.FONT_HERSHEY_SIMPLEX, 1.1, last_quality_color, 3)\n",
    "\n",
    "            # skeleton\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                )\n",
    "\n",
    "            out.write(image)\n",
    "            cv2.imshow(\"Smart Squat Trainer\", image)\n",
    "            key = cv2.waitKey(10) & 0xFF\n",
    "            if key in (ord('q'), 27):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        csv_file.close()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # summary\n",
    "        if rep_records:\n",
    "            avg_depth = np.mean([r[0] for r in rep_records])\n",
    "            avg_lean = np.mean([r[1] for r in rep_records])\n",
    "            good_count = sum(1 for r in rep_records if r[2]==\"Good\")\n",
    "            print(\"\\n=== SESSION SUMMARY ===\")\n",
    "            print(f\"Total Reps: {len(rep_records)}\")\n",
    "            print(f\"Average Depth (knee angle): {avg_depth:.1f}°\")\n",
    "            print(f\"Average Lean: {avg_lean:.1f}°\")\n",
    "            print(f\"Good Reps: {good_count} / {len(rep_records)} ({(good_count/len(rep_records))*100:.1f}%)\")\n",
    "            print(f\"Video saved: {video_path}\")\n",
    "            print(f\"CSV log: {csv_path}\")\n",
    "        else:\n",
    "            print(\"No reps recorded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c22b1-2199-4078-a637-bb0b69b63207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
